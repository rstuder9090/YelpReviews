{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96b1a262",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9f2d5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv('sushi_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa83ed2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips = pd.read_csv('sushi_tips.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5ba3886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>compliment_count</th>\n",
       "      <th>V6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>j2sEA3hiUcwHfq9Ml6M47g</td>\n",
       "      <td>EXYbKA1tocvOK_1tXxZXLA</td>\n",
       "      <td>Don't go for dinner. They close at 6. Really Y...</td>\n",
       "      <td>2011-10-13 03:15:15</td>\n",
       "      <td>0</td>\n",
       "      <td>dont go  dinner  close  6 really yvonne l nega...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>jDThlALkraoQLLBYHqY7FQ</td>\n",
       "      <td>9DJhhBqQSu-gTBwaqdhgpQ</td>\n",
       "      <td>Come early for the best service as they fill u...</td>\n",
       "      <td>2016-01-16 19:13:57</td>\n",
       "      <td>0</td>\n",
       "      <td>come early   best service   fill  really quickly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>xEM8BRJ4wm_s47Y0nL51MA</td>\n",
       "      <td>xv_U__GI9gmzKIHT_TANnw</td>\n",
       "      <td>Best General Tso around. Also, try the grilled...</td>\n",
       "      <td>2011-07-30 22:54:31</td>\n",
       "      <td>0</td>\n",
       "      <td>best general tso around also try  grilled swee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>cogPv5baWhsR-_Dcw3-Taw</td>\n",
       "      <td>-Xld662dL8WxrwP--bclIQ</td>\n",
       "      <td>The yum yum roll is delicious!</td>\n",
       "      <td>2011-05-01 01:48:56</td>\n",
       "      <td>0</td>\n",
       "      <td>yum yum roll  delicious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>jlN9luFsNZfZkxnM7cdLKQ</td>\n",
       "      <td>cv-SmPhbpwQCtlI2Q7KJIQ</td>\n",
       "      <td>Very good shanghai soup dumplings</td>\n",
       "      <td>2013-09-06 23:58:56</td>\n",
       "      <td>0</td>\n",
       "      <td>good shanghai soup dumplings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31567</th>\n",
       "      <td>31568</td>\n",
       "      <td>n28ACFmeqLzzTVpCP2m2Bw</td>\n",
       "      <td>xv_U__GI9gmzKIHT_TANnw</td>\n",
       "      <td>pepper steak combo.  it was soso</td>\n",
       "      <td>2019-11-07 18:12:05</td>\n",
       "      <td>0</td>\n",
       "      <td>pepper steak combo    soso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31568</th>\n",
       "      <td>31569</td>\n",
       "      <td>bHHTHTeM1Sb8-aun1pM8Tw</td>\n",
       "      <td>0OsR9lO16jxa0xWUY57s9g</td>\n",
       "      <td>Very good</td>\n",
       "      <td>2020-02-23 00:17:34</td>\n",
       "      <td>0</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31569</th>\n",
       "      <td>31570</td>\n",
       "      <td>he-2lO3-bv9IhZw4ugKujQ</td>\n",
       "      <td>_OMGZ3TXOfN2By7skat_bw</td>\n",
       "      <td>Jarrod is Awesome. He tickles me! Dinner is great</td>\n",
       "      <td>2016-07-26 00:45:36</td>\n",
       "      <td>0</td>\n",
       "      <td>jarrod  awesome  tickles  dinner  great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31570</th>\n",
       "      <td>31571</td>\n",
       "      <td>UAIp182w-jpNXqLvu-M34A</td>\n",
       "      <td>DJFxBTBIgYErzKS5cA_LiQ</td>\n",
       "      <td>This is probably my favorite sushi bar ever! G...</td>\n",
       "      <td>2018-03-29 23:04:32</td>\n",
       "      <td>0</td>\n",
       "      <td>probably  favorite sushi bar ever good food ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31571</th>\n",
       "      <td>31572</td>\n",
       "      <td>1uxtQAuJ2T5Xwa_wp7kUnA</td>\n",
       "      <td>OaGf0Dp56ARhQwIDT90w_g</td>\n",
       "      <td>Great food and service.</td>\n",
       "      <td>2021-10-30 11:54:36</td>\n",
       "      <td>0</td>\n",
       "      <td>great food  service</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31572 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                 user_id             business_id  \\\n",
       "0               1  j2sEA3hiUcwHfq9Ml6M47g  EXYbKA1tocvOK_1tXxZXLA   \n",
       "1               2  jDThlALkraoQLLBYHqY7FQ  9DJhhBqQSu-gTBwaqdhgpQ   \n",
       "2               3  xEM8BRJ4wm_s47Y0nL51MA  xv_U__GI9gmzKIHT_TANnw   \n",
       "3               4  cogPv5baWhsR-_Dcw3-Taw  -Xld662dL8WxrwP--bclIQ   \n",
       "4               5  jlN9luFsNZfZkxnM7cdLKQ  cv-SmPhbpwQCtlI2Q7KJIQ   \n",
       "...           ...                     ...                     ...   \n",
       "31567       31568  n28ACFmeqLzzTVpCP2m2Bw  xv_U__GI9gmzKIHT_TANnw   \n",
       "31568       31569  bHHTHTeM1Sb8-aun1pM8Tw  0OsR9lO16jxa0xWUY57s9g   \n",
       "31569       31570  he-2lO3-bv9IhZw4ugKujQ  _OMGZ3TXOfN2By7skat_bw   \n",
       "31570       31571  UAIp182w-jpNXqLvu-M34A  DJFxBTBIgYErzKS5cA_LiQ   \n",
       "31571       31572  1uxtQAuJ2T5Xwa_wp7kUnA  OaGf0Dp56ARhQwIDT90w_g   \n",
       "\n",
       "                                                    text                 date  \\\n",
       "0      Don't go for dinner. They close at 6. Really Y...  2011-10-13 03:15:15   \n",
       "1      Come early for the best service as they fill u...  2016-01-16 19:13:57   \n",
       "2      Best General Tso around. Also, try the grilled...  2011-07-30 22:54:31   \n",
       "3                         The yum yum roll is delicious!  2011-05-01 01:48:56   \n",
       "4                      Very good shanghai soup dumplings  2013-09-06 23:58:56   \n",
       "...                                                  ...                  ...   \n",
       "31567                   pepper steak combo.  it was soso  2019-11-07 18:12:05   \n",
       "31568                                          Very good  2020-02-23 00:17:34   \n",
       "31569  Jarrod is Awesome. He tickles me! Dinner is great  2016-07-26 00:45:36   \n",
       "31570  This is probably my favorite sushi bar ever! G...  2018-03-29 23:04:32   \n",
       "31571                            Great food and service.  2021-10-30 11:54:36   \n",
       "\n",
       "       compliment_count                                                 V6  \n",
       "0                     0  dont go  dinner  close  6 really yvonne l nega...  \n",
       "1                     0   come early   best service   fill  really quickly  \n",
       "2                     0  best general tso around also try  grilled swee...  \n",
       "3                     0                            yum yum roll  delicious  \n",
       "4                     0                       good shanghai soup dumplings  \n",
       "...                 ...                                                ...  \n",
       "31567                 0                         pepper steak combo    soso  \n",
       "31568                 0                                               good  \n",
       "31569                 0            jarrod  awesome  tickles  dinner  great  \n",
       "31570                 0    probably  favorite sushi bar ever good food ...  \n",
       "31571                 0                                great food  service  \n",
       "\n",
       "[31572 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0207497b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 17 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bag = reviews['V10'].tolist()\n",
    "bag = ' '.join(str(e) for e in bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "23b8a65c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 53.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bigram = list(ngrams(nltk.word_tokenize(bag), 2))  #gen bigrams from bag\n",
    "temp = dict(Counter(bigram))\n",
    "\n",
    "df = pd.DataFrame(list(temp.items()))\n",
    "\n",
    "df.columns = ['Bi-Gram', 'Frequency']\n",
    "df = df.loc[df.Frequency > 5] #filter more frequent grams 5 mentions or more\n",
    "df = df.sort_values(by=['Frequency'],ascending=False)\n",
    "df.to_csv('bigrams_all_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "270656c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 57.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trigram = list(ngrams(nltk.word_tokenize(bag), 3))  #gen trigrams from bag\n",
    "temp = dict(Counter(trigram))\n",
    "\n",
    "df = pd.DataFrame(list(temp.items()))\n",
    "\n",
    "df.columns = ['Tri-Gram', 'Frequency']\n",
    "df = df.loc[df.Frequency > 5] #filter more frequent grams 5 mentions or more\n",
    "df = df.sort_values(by=['Frequency'],ascending=False)\n",
    "df.to_csv('trigrams_all_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f7a82ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uni = pd.read_csv('unigrams_all_reviews.csv')\n",
    "df_bi = pd.read_csv('bigrams_all_reviews.csv')\n",
    "df_tri = pd.read_csv('trigrams_all_reviews.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "675edd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_grams = pd.concat([df_uni, df_bi, df_tri], axis=1)\n",
    "all_grams = all_grams.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "all_grams.to_csv('all_grams_all_reviews.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2ee6df",
   "metadata": {},
   "source": [
    "# Filter Reviews by star and make n-gram tables \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "04a4095b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#first loop for filter new dataset\n",
    "for i in range(1,6): #stars\n",
    "    current_star = f'{i}-Star'\n",
    "    temp_df = reviews.loc[reviews.stars == i]\n",
    "    \n",
    "    bag = ''\n",
    "    bag = temp_df['V10'].tolist()\n",
    "    bag = ' '.join(str(e) for e in bag)\n",
    "\n",
    "    #second loop for 1,2,3 grams\n",
    "    for j in range(1,4):\n",
    "        current_gram = f'{j}-Gram'\n",
    "        grams = list(ngrams(nltk.word_tokenize(bag), j))  #gen j-Grams\n",
    "        temp = dict(Counter(grams))\n",
    "        if j == 1:\n",
    "            gram_df = pd.DataFrame(list(temp.items()))\n",
    "            gram_df.columns = [current_gram, 'Frequency']\n",
    "            gram_df = gram_df.loc[gram_df.Frequency > 5] #filter more frequent grams 5 mentions or more\n",
    "            gram_df = gram_df.sort_values(by=['Frequency'],ascending=False)\n",
    "            \n",
    "        else:\n",
    "            temp = pd.DataFrame(list(temp.items()))\n",
    "            temp.columns = [current_gram, 'Frequency']\n",
    "            temp = temp.loc[temp.Frequency > 5] #filter more frequent grams 5 mentions or more\n",
    "            temp = temp.sort_values(by=['Frequency'],ascending=False)\n",
    "            temp.reset_index(drop=True, inplace=True)  #fix bug where indices cause ordering issue in df\n",
    "            gram_df.reset_index(drop=True, inplace=True)  #fix bug where indices cause ordering issue in df\n",
    "            gram_df = pd.concat([gram_df, temp], axis=1)\n",
    "    gram_df.to_csv(f'{current_star}-grams.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6409ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "stopwords = ['sushi', 'food', 'rolls', 'place', 'just', 'one']  #derived from overall n-gram table\n",
    "\n",
    "for business_id in set(reviews['business_id']):\n",
    "    #second loop to split reviews good v bad\n",
    "    for k in ['good', 'bad']:\n",
    "        if k == 'good': temp_df = reviews[(reviews.stars > 3) & (reviews.business_id == business_id)]\n",
    "        else: temp_df = reviews[(reviews.stars < 3) & (reviews.business_id == business_id)]\n",
    "        \n",
    "        if len(temp_df['V10']) < 10: pass\n",
    "        else:\n",
    "        \n",
    "            bag = ''\n",
    "            bag = temp_df['V10'].tolist()\n",
    "            bag = ' '.join(str(e) for e in bag)\n",
    "            bag = nltk.word_tokenize(bag)\n",
    "            tokens = [str(token) for token in bag if str(token) not in stopwords]\n",
    "            #third loop for 1,2,3 grams\n",
    "            for j in range(1,4):\n",
    "                current_gram = f'{j}-Gram'\n",
    "                \n",
    "                grams = list(ngrams(tokens, j))  #gen j-Grams\n",
    "                temp = dict(Counter(grams))\n",
    "                if j == 1:\n",
    "                    gram_df = pd.DataFrame(list(temp.items()))\n",
    "                    gram_df.columns = [current_gram, 'Frequency']\n",
    "                    gram_df[f'Percent Total {k} {j}-Grams'] = gram_df['Frequency']/sum(gram_df['Frequency'])\n",
    "                    #gram_df = gram_df.loc[gram_df.Frequency > 5] #filter more frequent grams 5 mentions or more\n",
    "                    gram_df = gram_df.sort_values(by=['Frequency'],ascending=False)\n",
    "                else:\n",
    "                    temp = pd.DataFrame(list(temp.items()))\n",
    "                    temp.columns = [current_gram, 'Frequency']\n",
    "                    temp[f'Percent Total {k} {j}-Grams'] = temp['Frequency']/sum(temp['Frequency'])\n",
    "                    temp = temp.sort_values(by=['Frequency'],ascending=False)\n",
    "                    temp.reset_index(drop=True, inplace=True)  #fix bug where indices cause ordering issue in df\n",
    "                    gram_df.reset_index(drop=True, inplace=True)  #fix bug where indices cause ordering issue in df\n",
    "                    gram_df = pd.concat([gram_df, temp], axis=1)\n",
    "            \n",
    "            gram_df.truncate(0, 99).to_csv(f'app_data/review-grams/{business_id}-{k}-grams.csv')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5722fd",
   "metadata": {},
   "source": [
    "# Filter Tips by business and make n-gram tables \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "283544fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "stopwords = ['sushi', 'food', 'rolls', 'place', 'just', 'one']  #derived from overall n-gram table\n",
    "\n",
    "for business_id in set(tips['business_id']):\n",
    "    temp_df = tips[tips.business_id == business_id]\n",
    "        \n",
    "    if len(temp_df['V6']) < 5: pass\n",
    "    else:\n",
    "\n",
    "        bag = ''\n",
    "        bag = temp_df['V6'].tolist()\n",
    "        bag = ' '.join(str(e) for e in bag)\n",
    "        bag = nltk.word_tokenize(bag)\n",
    "        tokens = [str(token) for token in bag if str(token) not in stopwords]\n",
    "        #third loop for 1,2,3 grams\n",
    "        for j in range(1,4):\n",
    "            current_gram = f'{j}-Gram'\n",
    "\n",
    "            grams = list(ngrams(tokens, j))  #gen j-Grams\n",
    "            temp = dict(Counter(grams))\n",
    "            if j == 1:\n",
    "                gram_df = pd.DataFrame(list(temp.items()))\n",
    "                gram_df.columns = [current_gram, 'Frequency']\n",
    "                gram_df[f'Percent Total {j}-Grams'] = gram_df['Frequency']/sum(gram_df['Frequency'])\n",
    "                gram_df = gram_df.sort_values(by=['Frequency'],ascending=False)\n",
    "            else:\n",
    "                temp = pd.DataFrame(list(temp.items()))\n",
    "                temp.columns = [current_gram, 'Frequency']\n",
    "                temp[f'Percent Total {j}-Grams'] = temp['Frequency']/sum(temp['Frequency'])\n",
    "                temp = temp.sort_values(by=['Frequency'],ascending=False)\n",
    "                temp.reset_index(drop=True, inplace=True)  #fix bug where indices cause ordering issue in df\n",
    "                gram_df.reset_index(drop=True, inplace=True)  #fix bug where indices cause ordering issue in df\n",
    "                gram_df = pd.concat([gram_df, temp], axis=1)\n",
    "\n",
    "        gram_df.truncate(0, 99).to_csv(f'app_data/tip-grams/{business_id}-grams.csv')    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
